{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Athenaeum Playground\n",
    "\n",
    "This notebook walks through the core features of **Athenaeum** — a Python library for building searchable knowledge bases from documents.\n",
    "\n",
    "We will:\n",
    "1. Install dependencies\n",
    "2. Initialize a knowledge base\n",
    "3. Load PDF papers with tags\n",
    "4. List and filter documents\n",
    "5. Search across documents (BM25, vector, hybrid)\n",
    "6. Search within a single document\n",
    "7. Read specific excerpts\n",
    "8. Manage tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q athenaeum-kb langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup\n",
    "\n",
    "Make sure your `OPENAI_API_KEY` environment variable is set before running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from athenaeum import Athenaeum, AthenaeumConfig\n",
    "\n",
    "DOCS_DIR = Path(\"knowledge-base\")\n",
    "\n",
    "config = AthenaeumConfig(\n",
    "    storage_dir=Path(\"athenaeum-data\"),\n",
    "    chunk_size=40,\n",
    "    chunk_overlap=10,\n",
    ")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "kb = Athenaeum(embeddings=embeddings, config=config)\n",
    "\n",
    "print(\"Knowledge base ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load documents\n",
    "\n",
    "We load the PDF papers from `knowledge-base/`, assigning tags by research area so we can filter later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = {\n",
    "    \"Attention Is All You Need.pdf\": {\"nlp\", \"transformers\", \"architecture\"},\n",
    "    \"BERT.pdf\":                      {\"nlp\", \"transformers\", \"pretraining\"},\n",
    "    \"XLNet.pdf\":                     {\"nlp\", \"transformers\", \"pretraining\"},\n",
    "    \"Language Models are Few-Shot Learners.pdf\": {\"nlp\", \"transformers\", \"pretraining\", \"generative\"},\n",
    "    \"LORA.pdf\":                      {\"nlp\", \"transformers\", \"fine-tuning\"},\n",
    "    \"RAG.pdf\":                       {\"nlp\", \"transformers\", \"retrieval\"},\n",
    "    \"ViT.pdf\":                       {\"vision\", \"transformers\", \"architecture\"},\n",
    "    \"GANs.pdf\":                      {\"vision\", \"generative\"},\n",
    "    \"VAE.pdf\":                       {\"vision\", \"generative\"},\n",
    "    \"DDPM.pdf\":                      {\"vision\", \"generative\", \"diffusion\"},\n",
    "    \"High-Resolution Image Synthesis with Latent Diffusion Models.pdf\": {\"vision\", \"generative\", \"diffusion\"},\n",
    "}\n",
    "\n",
    "doc_ids = {}\n",
    "for filename, tags in papers.items():\n",
    "    path = DOCS_DIR / filename\n",
    "    if not path.exists():\n",
    "        print(f\"Skipping (not found): {filename}\")\n",
    "        continue\n",
    "    doc_id = kb.load_doc(str(path), tags=tags)\n",
    "    doc_ids[filename] = doc_id\n",
    "    print(f\"Loaded: {filename} -> {doc_id}  (tags: {tags})\")\n",
    "\n",
    "print(f\"\\nTotal documents: {len(doc_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. List documents\n",
    "\n",
    "### All documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in kb.list_docs():\n",
    "    print(f\"{doc.id}  {doc.name:<60}  tags={doc.tags}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by tags\n",
    "\n",
    "Tags use **OR semantics** — any document matching at least one of the given tags is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Diffusion papers ===\")\n",
    "for doc in kb.list_docs(tags={\"diffusion\"}):\n",
    "    print(f\"  {doc.name}\")\n",
    "\n",
    "print(\"\\n=== NLP papers ===\")\n",
    "for doc in kb.list_docs(tags={\"nlp\"}):\n",
    "    print(f\"  {doc.name}\")\n",
    "\n",
    "print(\"\\n=== Vision OR fine-tuning ===\")\n",
    "for doc in kb.list_docs(tags={\"vision\", \"fine-tuning\"}):\n",
    "    print(f\"  {doc.name}  tags={doc.tags}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all tags in the knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All tags:\", sorted(kb.list_tags()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Search across documents\n",
    "\n",
    "### BM25 (keyword) search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = kb.search_docs(\"self-attention mechanism\", top_k=5, strategy=\"bm25\")\n",
    "\n",
    "print(\"Query: 'self-attention mechanism' (BM25)\\n\")\n",
    "for hit in results:\n",
    "    print(f\"  [{hit.score:.3f}] {hit.name}\")\n",
    "    if hit.snippet:\n",
    "        print(f\"          {hit.snippet[:120]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector (semantic) search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = kb.search_docs(\"how to generate realistic images\", top_k=5, strategy=\"vector\")\n",
    "\n",
    "print(\"Query: 'how to generate realistic images' (vector)\\n\")\n",
    "for hit in results:\n",
    "    print(f\"  [{hit.score:.3f}] {hit.name}\")\n",
    "    if hit.snippet:\n",
    "        print(f\"          {hit.snippet[:120]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid search (default)\n",
    "\n",
    "Combines BM25 and vector search with Reciprocal Rank Fusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = kb.search_docs(\"low-rank adaptation for large language models\", top_k=5)\n",
    "\n",
    "print(\"Query: 'low-rank adaptation for large language models' (hybrid)\\n\")\n",
    "for hit in results:\n",
    "    print(f\"  [{hit.score:.4f}] {hit.name}\")\n",
    "    if hit.snippet:\n",
    "        print(f\"           {hit.snippet[:120]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search with tag filtering\n",
    "\n",
    "Restrict search to documents matching specific tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== 'generative models' scoped to vision papers ===\")\n",
    "for hit in kb.search_docs(\"generative models\", top_k=5, tags={\"vision\"}):\n",
    "    print(f\"  [{hit.score:.4f}] {hit.name}\")\n",
    "\n",
    "print(\"\\n=== 'generative models' scoped to NLP papers ===\")\n",
    "for hit in kb.search_docs(\"generative models\", top_k=5, tags={\"nlp\"}):\n",
    "    print(f\"  [{hit.score:.4f}] {hit.name}\")\n",
    "\n",
    "print(\"\\n=== 'generative models' with no tag filter (all docs) ===\")\n",
    "for hit in kb.search_docs(\"generative models\", top_k=5):\n",
    "    print(f\"  [{hit.score:.4f}] {hit.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = kb.search_docs(\"BERT\", scope=\"names\")\n",
    "\n",
    "print(\"Name search: 'BERT'\\n\")\n",
    "for hit in results:\n",
    "    print(f\"  {hit.name}  (score={hit.score})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Search within a document\n",
    "\n",
    "Pick a specific paper and search for content inside it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_id = doc_ids[\"Attention Is All You Need.pdf\"]\n",
    "\n",
    "results = kb.search_doc_contents(attention_id, \"positional encoding\", top_k=3)\n",
    "\n",
    "print(f\"Searching inside 'Attention Is All You Need' for 'positional encoding'\\n\")\n",
    "for hit in results:\n",
    "    print(f\"  Lines {hit.line_range[0]}-{hit.line_range[1]}  (score={hit.score:.3f})\")\n",
    "    print(f\"  {hit.text[:200]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Read specific excerpts\n",
    "\n",
    "Read exact line ranges from a document — useful for presenting context to an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the first 30 lines of a paper\n",
    "gpt3_id = doc_ids[\"Language Models are Few-Shot Learners.pdf\"]\n",
    "excerpt = kb.read_doc(gpt3_id, start_line=1, end_line=30)\n",
    "\n",
    "print(f\"Document: Language Models are Few-Shot Learners\")\n",
    "print(f\"Lines {excerpt.line_range[0]}-{excerpt.line_range[1]} of {excerpt.total_lines}\\n\")\n",
    "print(excerpt.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use table of contents to navigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the TOC of a paper\n",
    "lora_id = doc_ids[\"LORA.pdf\"]\n",
    "lora_docs = [d for d in kb.list_docs() if d.id == lora_id]\n",
    "\n",
    "print(\"Table of Contents — LORA\\n\")\n",
    "print(lora_docs[0].table_of_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Manage tags\n",
    "\n",
    "Tags can be added or removed after loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a tag\n",
    "kb.tag_doc(attention_id, {\"seminal\", \"google\"})\n",
    "\n",
    "# Check\n",
    "doc = [d for d in kb.list_docs() if d.id == attention_id][0]\n",
    "print(f\"{doc.name} tags after adding: {doc.tags}\")\n",
    "\n",
    "# Remove a tag\n",
    "kb.untag_doc(attention_id, {\"google\"})\n",
    "\n",
    "doc = [d for d in kb.list_docs() if d.id == attention_id][0]\n",
    "print(f\"{doc.name} tags after removing 'google': {doc.tags}\")\n",
    "\n",
    "# List all tags across the knowledge base\n",
    "print(f\"\\nAll tags: {sorted(kb.list_tags())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cleanup\n",
    "\n",
    "The knowledge base persists in `athenaeum-data/`. Delete it to start fresh:\n",
    "\n",
    "```python\n",
    "import shutil\n",
    "shutil.rmtree(\"athenaeum-data\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
