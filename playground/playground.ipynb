{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Athenaeum Playground\n",
    "\n",
    "This notebook walks through the core features of **Athenaeum** — a Python library for building searchable knowledge bases from documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 11ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Use one of the following:\n",
    "\n",
    "#!pip install -q athenaeum-kb[mistral]\n",
    "!uv pip install '../dist/athenaeum_kb-0.2.1-py3-none-any.whl[mistral]' -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY:  ········\n",
      "MISTRAL_API_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "OPENAI_API_KEY = getpass.getpass('OPENAI_API_KEY: ')\n",
    "MISTRAL_API_KEY = getpass.getpass('MISTRAL_API_KEY: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DOCS_DIR = Path(\"knowledge-base\")\n",
    "STORAGE_DIR = Path(\".athenaeum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, Language\n",
    "from athenaeum import Athenaeum, AthenaeumConfig, get_ocr_provider\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import tiktoken\n",
    "\n",
    "config = AthenaeumConfig(\n",
    "    storage_dir=STORAGE_DIR,\n",
    "    rrf_k=70,                   # RRF constant for hybrid search\n",
    "    default_strategy=\"hybrid\",  # Default search strategy\n",
    ")\n",
    "\n",
    "# Custom token-based splitter\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "token_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    Language.MARKDOWN,\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=64,\n",
    "    length_function=lambda text: len(enc.encode(text)),\n",
    ")\n",
    "\n",
    "# Embedding model\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", api_key=OPENAI_API_KEY)\n",
    "\n",
    "# OCR model\n",
    "ocr = get_ocr_provider(\"mistral\", api_key=MISTRAL_API_KEY)\n",
    "\n",
    "kb = Athenaeum(\n",
    "    config=config,\n",
    "    ocr_provider=ocr,\n",
    "    embeddings=embeddings,\n",
    "    text_splitter=token_splitter\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded Attention Is All You Need.pdf with ID a37ca72e7343\n",
      "[INFO] Loaded BERT.pdf with ID a93623c887f3\n",
      "[INFO] Loaded XLNet.pdf with ID 398c7fcbc1bb\n",
      "[INFO] Loaded Language Models are Few-Shot Learners.pdf with ID 558dfc0f6033\n",
      "[INFO] Loaded LORA.pdf with ID 56397b5e8269\n",
      "[INFO] Loaded RAG.pdf with ID 30ea5715ee9d\n",
      "[INFO] Loaded ViT.pdf with ID f83a251d3a8d\n",
      "[INFO] Loaded GANs.pdf with ID 8053b5f17066\n",
      "[INFO] Loaded VAE.pdf with ID 77f686645c39\n",
      "[INFO] Loaded DDPM.pdf with ID 7e2a0c030dc2\n",
      "[INFO] Loaded High-Resolution Image Synthesis with Latent Diffusion Models.pdf with ID f3ea54df7f8d\n"
     ]
    }
   ],
   "source": [
    "# Load the PDF papers from `DOCS_DIR`, assigning tags by research area so we can filter later\n",
    "\n",
    "papers = {\n",
    "    \"Attention Is All You Need.pdf\": {\"nlp\", \"transformers\", \"architecture\"},\n",
    "    \"BERT.pdf\":                      {\"nlp\", \"transformers\", \"pretraining\"},\n",
    "    \"XLNet.pdf\":                     {\"nlp\", \"transformers\", \"pretraining\"},\n",
    "    \"Language Models are Few-Shot Learners.pdf\": {\"nlp\", \"transformers\", \"pretraining\", \"generative\"},\n",
    "    \"LORA.pdf\":                      {\"nlp\", \"transformers\", \"fine-tuning\"},\n",
    "    \"RAG.pdf\":                       {\"nlp\", \"transformers\", \"retrieval\"},\n",
    "    \"ViT.pdf\":                       {\"vision\", \"transformers\", \"architecture\"},\n",
    "    \"GANs.pdf\":                      {\"vision\", \"generative\"},\n",
    "    \"VAE.pdf\":                       {\"vision\", \"generative\"},\n",
    "    \"DDPM.pdf\":                      {\"vision\", \"generative\", \"diffusion\"},\n",
    "    \"High-Resolution Image Synthesis with Latent Diffusion Models.pdf\": {\"vision\", \"generative\", \"diffusion\"},\n",
    "}\n",
    "\n",
    "for filename, tags in papers.items():\n",
    "    path = DOCS_DIR / filename\n",
    "    if not path.exists():\n",
    "        print(f\"Skipping (not found): {filename}\")\n",
    "        continue\n",
    "    doc_id = kb.load_doc(str(path), tags=tags)\n",
    "    print(f\"[INFO] Loaded {filename} with ID {doc_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a37ca72e7343  Attention Is All You Need.pdf                               \n",
      "a93623c887f3  BERT.pdf                                                    \n",
      "398c7fcbc1bb  XLNet.pdf                                                   \n",
      "558dfc0f6033  Language Models are Few-Shot Learners.pdf                   \n",
      "56397b5e8269  LORA.pdf                                                    \n",
      "30ea5715ee9d  RAG.pdf                                                     \n",
      "f83a251d3a8d  ViT.pdf                                                     \n",
      "8053b5f17066  GANs.pdf                                                    \n",
      "77f686645c39  VAE.pdf                                                     \n",
      "7e2a0c030dc2  DDPM.pdf                                                    \n",
      "f3ea54df7f8d  High-Resolution Image Synthesis with Latent Diffusion Models.pdf\n"
     ]
    }
   ],
   "source": [
    "# List all documents in kb\n",
    "\n",
    "docs = kb.list_docs()\n",
    "for doc in docs:\n",
    "    print(f\"{doc.id}  {doc.name:<60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Filter by tags\n# Tags use OR semantics — any document matching at least one of the given tags is returned.\n\nprint(\"Diffusion papers:\")\nfor doc in kb.list_docs(tags={\"diffusion\"}):\n    print(f\"  - {doc.name}\")\n\nprint()\nprint(\" NLP papers:\")\nfor doc in kb.list_docs(tags={\"nlp\"}):\n    print(f\"  - {doc.name}\")\n\nprint()\nprint(\"Vision + fine-tuning:\")\nfor doc in kb.list_docs(tags={\"vision\", \"fine-tuning\"}):\n    print(f\"  - {doc.name}  tags={kb.get_tags(doc.id)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags:\n",
      " - architecture\n",
      " - diffusion\n",
      " - fine-tuning\n",
      " - generative\n",
      " - nlp\n",
      " - pretraining\n",
      " - retrieval\n",
      " - transformers\n",
      " - vision\n"
     ]
    }
   ],
   "source": [
    "# List all tags in the kb\n",
    "\n",
    "tags = kb.list_tags()\n",
    "\n",
    "print(\"Tags:\")\n",
    "for tag in sorted(tags):\n",
    "    print(f\" - {tag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search across documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# BM25 (keyword) search\nquery = \"self-attention mechanism\"\nresults = kb.search_kb(query, top_k=3, strategy=\"bm25\")\n\nfor hit in results:\n    print(f\"[{hit.score:.3f}] {hit.name}\")\n    if hit.snippet:\n        print(f\"{hit.snippet[:120]}...\")\n        print()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": "# Vector (semantic) search\nquery = \"how to generate realistic images?\"\nresults = kb.search_kb(query, top_k=3, strategy=\"vector\")\n\nfor hit in results:\n    print(f\"[{hit.score:.3f}] {hit.name}\")\n    if hit.snippet:\n        print(f\"{hit.snippet[:120]}...\")\n        print()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Hybrid search (default)\n# Combines BM25 and vector search with Reciprocal Rank Fusion.\nquery = \"low-rank adaptation for large language models\"\nresults = kb.search_kb(query, top_k=3)\n\nfor hit in results:\n    print(f\"[{hit.score:.4f}] {hit.name}\")\n    if hit.snippet:\n        print(f\"{hit.snippet[:120]}...\")\n        print()"
  },
  {
   "cell_type": "code",
   "source": "# Similarity threshold — filter out low-confidence vector results\n# Set similarity_threshold in AthenaeumConfig to drop chunks below a cosine score cutoff.\n# Scores are in [0, 1]; a threshold of 0.35 keeps only reasonably similar chunks.\n#\n# Note: similarity_threshold only affects \"vector\" and \"hybrid\" strategies (not \"bm25\").\n# To use this feature, create a new Athenaeum instance with the desired config:\n#\n#   from athenaeum import Athenaeum, AthenaeumConfig\n#   config = AthenaeumConfig(storage_dir=STORAGE_DIR, similarity_threshold=0.35)\n#   kb_filtered = Athenaeum(embeddings=embeddings, config=config)\n#\n# For demonstration, we show the raw scores returned by vector search so you can\n# choose an appropriate threshold for your use case.\n\nquery = \"how to generate realistic images?\"\nresults = kb.search_kb(query, top_k=5, strategy=\"vector\")\n\nprint(f\"Vector search results for: '{query}'\")\nprint(f\"(use similarity_threshold in AthenaeumConfig to filter below a chosen score)\\n\")\nfor hit in results:\n    print(f\"  [{hit.score:.3f}] {hit.name}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Chunk-level results with aggregate=False\n# By default search_kb returns one SearchHit per document (aggregate=True).\n# Pass aggregate=False to get raw ContentSearchHit objects with exact line ranges,\n# which is useful when you need to pinpoint exactly where a match appears.\n\nquery = \"low-rank adaptation for large language models\"\nchunks = kb.search_kb(query, top_k=5, aggregate=False)\n\nprint(f\"Chunk-level results for: '{query}'\\n\")\nfor hit in chunks:\n    print(f\"  [{hit.score:.4f}] {hit.name}  lines {hit.line_range[0]}-{hit.line_range[1]}\")\n    print(f\"           {hit.text[:100].strip()}...\")\n    print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Search with tag filtering\n# Restrict search to documents matching specific tags.\nquery = \"generative models\"\nresults = kb.search_kb(query, top_k=3, tags={\"nlp\"})\n\nfor hit in results:\n    print(f\"[{hit.score:.4f}] {hit.name}\")\n    if hit.snippet:\n        print(f\"{hit.snippet[:120]}...\")\n        print()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Search by name\nquery = \"BERT\"\nresults = kb.search_kb(query, scope=\"names\", strategy=\"bm25\")\n\nfor hit in results:\n    print(f\"[{hit.score:.4f}] {hit.name}\")\n    if hit.snippet:\n        print(f\"{hit.snippet[:120]}...\")\n        print()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search within a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": "# Pick a specific paper and search for content inside it\n\ndoc_ids = {doc.name: doc.id for doc in docs}\nattention_id = doc_ids[\"BERT.pdf\"]\nquery = \"What is SQuAD?\"\n\nresults = kb.search_doc(attention_id, query, top_k=3)\nfor hit in results:\n    print(f\"[{hit.score:.3f}] {hit.line_range[0]}-{hit.line_range[1]}\")\n    print(f\"{hit.text[:100]}...\")\n    print()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Pick a specific paper and search for content inside it\n\ndoc_ids = {doc.name: doc.id for doc in docs}\nattention_id = doc_ids[\"BERT.pdf\"]\nquery = \"Describe BERT's model architecture\"\n\nresults = kb.search_doc(attention_id, query, top_k=3)\nfor hit in results:\n    print(f\"[{hit.score:.3f}] {hit.line_range[0]}-{hit.line_range[1]}\")\n    print(f\"{hit.text[:100]}...\")\n    print()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read specific excerpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines 1-20 of 1791\n",
      "\n",
      "# Language Models are Few-Shot Learners\n",
      "\n",
      "|  Tom B. Brown* |   | Benjamin Mann* |   | Nick Ryder* |   | Melanie Subbiah*  |   |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "|  Jared Kaplan† | Prafulla Dhariwal | Arvind Neelakantan | Pranav Shyam | Girish Sastry |  |  |   |\n",
      "|  Amanda Askell | Sandhini Agarwal | Ariel Herbert-Voss | Gretchen Krueger | Tom Henighan |  |  |   |\n",
      "|  Rewon Child | Aditya Ramesh | Daniel M. Ziegler | Jeffrey Wu | Clemens Winter |  |  |   |\n",
      "|  Christopher Hesse | Mark Chen | Eric Sigler | Mateusz Litwin | Scott Gray |  |  |   |\n",
      "|  Benjamin Chess |   | Jack Clark |   | Christopher Berner |   |  |   |\n",
      "|  Sam McCandlish |   | Alec Radford | Ilya Sutskever | Dario Amodei |   |  |   |\n",
      "\n",
      "OpenAI\n",
      "\n",
      "# Abstract\n",
      "\n",
      "Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions – something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters,  $10\\mathrm{x}$  more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.\n",
      "\n",
      "Author contributions listed at end of paper.\n",
      "\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Read the first 30 lines of a paper\n",
    "\n",
    "gpt3_id = doc_ids[\"Language Models are Few-Shot Learners.pdf\"]\n",
    "excerpt = kb.read_doc(gpt3_id, start_line=1, end_line=20)\n",
    "\n",
    "print(f\"Lines {excerpt.line_range[0]}-{excerpt.line_range[1]} of {excerpt.total_lines}\\n\")\n",
    "print(excerpt.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use table of contents to navigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "lora_id = doc_ids[\"LORA.pdf\"]\nprint(kb.get_toc(lora_id))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "vit_id = doc_ids[\"ViT.pdf\"]\nprint(kb.get_toc(vit_id))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage tags\n",
    "\n",
    "Tags can be added or removed after loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a tag\n",
    "kb.tag_doc(attention_id, {\"seminal\", \"google\"})\n",
    "\n",
    "# Remove a tag\n",
    "kb.untag_doc(attention_id, {\"google\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "The knowledge base persists in `STORAGE_DIR`. Delete it to start fresh:\n",
    "\n",
    "```python\n",
    "import shutil\n",
    "shutil.rmtree(STORAGE_DIR)\n",
    "```\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}